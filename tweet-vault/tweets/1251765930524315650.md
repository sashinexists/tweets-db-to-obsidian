---
id: 1251765930524315650
author: omaclaren
published_date: 2020-04-19 06:53:49 +00:00
conversation_id: 1251639295447691264
in_reply_to: 1251760783094018049
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- between
- work
- recent
- differences
- nets
- learn
- inverse
- machine
- ml
- learning
- literature
- models
- surrogate
- mimic
- cool
- lots
- neural
- using
- often
- stuff

---

@yudapearl @unsorsodicorda I’d caution/note that there’s differences between the more recent machine learning literature and the inverse problems/statistics literature. Lots of cool stuff in ML but often rediscovering exisiting work and/or just using neural nets to learn surrogate models (ie mimic DEs)

[View tweet on Twitter.com](https://twitter.com/omaclaren/status/1251765930524315650)

### Metadata

Author: [[@omaclaren]]
Conversation: [[conversation-1251639295447691264]]
In reply to: [[1251760783094018049]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2020-04-19]]
keywords:
- [[index/between|between]]
- [[index/work|work]]
- [[index/recent|recent]]
- [[index/differences|differences]]
- [[index/nets|nets]]
- [[index/learn|learn]]
- [[index/inverse|inverse]]
- [[index/machine|machine]]
- [[index/ml|ml]]
- [[index/learning|learning]]
- [[index/literature|literature]]
- [[index/models|models]]
- [[index/surrogate|surrogate]]
- [[index/mimic|mimic]]
- [[index/cool|cool]]
- [[index/lots|lots]]
- [[index/neural|neural]]
- [[index/using|using]]
- [[index/often|often]]
- [[index/stuff|stuff]]
