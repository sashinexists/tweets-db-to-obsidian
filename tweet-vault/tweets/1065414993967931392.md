---
id: 1065414993967931392
author: dustinvtran
published_date: 2018-11-22 01:21:43 +00:00
conversation_id: 1065280340669816832
in_reply_to: 1065374995411607552
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- work
- doing
- methods
- robust
- however
- all
- interestingly
- causal
- ci
- learning
- exception
- inference
- rl
- doubly
- environment
- much
- via
- policy
- interactions
- i
- operator
- seen
- value
- interpret

---

@zacharylipton @eliasbareinboim @CsabaSzepesvari @GaryMarcus @earnmyturns @yudapearl @ShalitUri All the work with (online) RL is also doing causal inference. You can interpret interactions with the environment via a do operator. Interestingly, however, I haven't seen much value out of merging CI with RL. One exception is doubly robust methods for offline policy learning

[View tweet on Twitter.com](https://twitter.com/dustinvtran/status/1065414993967931392)

### Metadata

Author: [[@dustinvtran]]
Conversation: [[conversation-1065280340669816832]]
In reply to: [[1065374995411607552]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2018-11-22]]
keywords:
- [[index/work|work]]
- [[index/doing|doing]]
- [[index/methods|methods]]
- [[index/robust|robust]]
- [[index/however|however]]
- [[index/all|all]]
- [[index/interestingly|interestingly]]
- [[index/causal|causal]]
- [[index/ci|ci]]
- [[index/learning|learning]]
- [[index/exception|exception]]
- [[index/inference|inference]]
- [[index/rl|rl]]
- [[index/doubly|doubly]]
- [[index/environment|environment]]
- [[index/much|much]]
- [[index/via|via]]
- [[index/policy|policy]]
- [[index/interactions|interactions]]
- [[index/i|i]]
- [[index/operator|operator]]
- [[index/seen|seen]]
- [[index/value|value]]
- [[index/interpret|interpret]]
