---
id: 1318078418592821248
author: yudapearl
published_date: 2020-10-19 06:35:58 +00:00
conversation_id: 1317532392442286080
in_reply_to: 1318062949244821507
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- why
- tasks
- wishing
- believe
- others
- see
- models
- require
- external
- neural
- i
- hard
- simply
- possibility
- certain
- away
- networks
- generalize

---

@jacobmbuckman @danijarh I believe you are wishing away the possibility that model-blind neural networks simply do NOT generalize, see      https://t.co/dEPwcuLbPS. Why is it so hard to internalize?
Certain tasks require external models, others do not.

[View tweet on Twitter.com](https://twitter.com/yudapearl/status/1318078418592821248)

### Metadata

Author: [[@yudapearl]]
Conversation: [[conversation-1317532392442286080]]
In reply to: [[1318062949244821507]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2020-10-19]]
keywords:
- [[index/why|why]]
- [[index/tasks|tasks]]
- [[index/wishing|wishing]]
- [[index/believe|believe]]
- [[index/others|others]]
- [[index/see|see]]
- [[index/models|models]]
- [[index/require|require]]
- [[index/external|external]]
- [[index/neural|neural]]
- [[index/i|i]]
- [[index/hard|hard]]
- [[index/simply|simply]]
- [[index/possibility|possibility]]
- [[index/certain|certain]]
- [[index/away|away]]
- [[index/networks|networks]]
- [[index/generalize|generalize]]
