---
id: 1326157460344856577
author: danijarh
published_date: 2020-11-10 13:39:12 +00:00
conversation_id: 1323599268939063302
in_reply_to: 1325947163558490120
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- sum
- agreed
- causal
- see
- tries
- rewards
- rl
- model
- distribution
- i
- agent
- think
- reach
- value
- input
- function

---

@jacobmbuckman @yudapearl Agreed that a value function is a causal model of the sum of rewards. I think you can also see a value function as an energy-based model of the input distribution in entropy-regularized RL, where the agent tries to reach p(x_t) = exp(V^pi(x_t))/Z.

[View tweet on Twitter.com](https://twitter.com/danijarh/status/1326157460344856577)

### Metadata

Author: [[@danijarh]]
Conversation: [[conversation-1323599268939063302]]
In reply to: [[1325947163558490120]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2020-11-10]]
keywords:
- [[index/sum|sum]]
- [[index/agreed|agreed]]
- [[index/causal|causal]]
- [[index/see|see]]
- [[index/tries|tries]]
- [[index/rewards|rewards]]
- [[index/rl|rl]]
- [[index/model|model]]
- [[index/distribution|distribution]]
- [[index/i|i]]
- [[index/agent|agent]]
- [[index/think|think]]
- [[index/reach|reach]]
- [[index/value|value]]
- [[index/input|input]]
- [[index/function|function]]
