---
id: 1318062216453738496
author: 811646204635287552
published_date: 2020-10-19 05:31:35 +00:00
conversation_id: 1317532392442286080
---
@yudapearl @danijarh Thus, RL gives us our policy π as:
π(&lt;S,H&gt;) = A1
π(&lt;S,M&gt;) = A2.

Of course, I cheated and made the problem a bit easier by assuming Markovian-ness. What if we remove this assumption, and make it a POMDP, which is more in the spirit of the original problem? 4/