---
id: 1053539752782123008
author:RandomlyWalking
published_date:{{PUBLISHED_DATE }}
conversation_id: Conversation-1052680788389507073
in_reply_to: 1053533521921269761
retweet: None
quoted_tweet: None
---

@yudapearl @tdietterich Lots of people who do "interpretable ML" agree that a big problem is that it's hard to know what we want. OTOH I can't define "clear computer program" either, but that does seem an important thing to aim at. Do all software engineers have implicit causal model of their code?

### Metadata

Author: [[@RandomlyWalking]]
Conversation: [[Conversation-1052680788389507073]]
In reply to: [[1053533521921269761]]
Retweet of: [[None]]
Quoted tweet: [[None]]
