---
id: 1395686803571494917
author: yudapearl
published_date: 2021-05-21 10:23:59 +00:00
conversation_id: 1395680936549916676
in_reply_to: 1395680936549916676
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- interpreting
- why
- understand
- need
- predictive
- causal
- ml
- make
- article
- main
- articles
- assumptions
- applied
- normal
- model
- students
- i
- internalize
- point
- often

---

@gottfriedmath Their conclusion: "The main point of this article is that the assumptions we make by interpreting a normal predictive model as causal are often unrealistic." I can understand why students of ML need more applied articles to internalize this point.

[View tweet on Twitter.com](https://twitter.com/yudapearl/status/1395686803571494917)

### Metadata

Author: [[@yudapearl]]
Conversation: [[conversation-1395680936549916676]]
In reply to: [[1395680936549916676]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2021-05-21]]
keywords:
- [[index/interpreting|interpreting]]
- [[index/why|why]]
- [[index/understand|understand]]
- [[index/need|need]]
- [[index/predictive|predictive]]
- [[index/causal|causal]]
- [[index/ml|ml]]
- [[index/make|make]]
- [[index/article|article]]
- [[index/main|main]]
- [[index/articles|articles]]
- [[index/assumptions|assumptions]]
- [[index/applied|applied]]
- [[index/normal|normal]]
- [[index/model|model]]
- [[index/students|students]]
- [[index/i|i]]
- [[index/internalize|internalize]]
- [[index/point|point]]
- [[index/often|often]]
