---
id: 1297936223692972032
author:GaryMarcus
published_date:{{PUBLISHED_DATE }}
conversation_id: Conversation-1296678240271171585
in_reply_to: 1297924683472318465
retweet: None
quoted_tweet: None
---

@tdietterich @neuro_data @KordingLab @tdverstynen @danilobzdok @lakens @TonyZador @ylecun @criticalneuro @IrisVanRooij @neurograce @achristensen56 @AudeOliva @BlackInNeuro @BlackWomenInAI @tyrell_turing and—crucially— is the architecture of GPT even *compatible* with the representation and learning of causal relations? or do you have to start over? n-grams aren’t compatible; why think GPT’s embedding, which often conflate many variables, are?

cc @yudapearl

### Metadata

Author: [[@GaryMarcus]]
Conversation: [[Conversation-1296678240271171585]]
In reply to: [[1297924683472318465]]
Retweet of: [[None]]
Quoted tweet: [[None]]
