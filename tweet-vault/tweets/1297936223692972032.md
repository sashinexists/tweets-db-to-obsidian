---
id: 1297936223692972032
author: GaryMarcus
published_date: 2020-08-24 16:38:04 +00:00
conversation_id: 1296678240271171585
in_reply_to: 1297924683472318465
retweet: None
quoted_tweet: None
type: tweet
tags:
-
---

@tdietterich @neuro_data @KordingLab @tdverstynen @danilobzdok @lakens @TonyZador @ylecun @criticalneuro @IrisVanRooij @neurograce @achristensen56 @AudeOliva @BlackInNeuro @BlackWomenInAI @tyrell_turing and—crucially— is the architecture of GPT even *compatible* with the representation and learning of causal relations? or do you have to start over? n-grams aren’t compatible; why think GPT’s embedding, which often conflate many variables, are?

cc @yudapearl

### Metadata

Author: [[@GaryMarcus]]
Conversation: [[conversation-1296678240271171585]]
In reply to: [[1297924683472318465]]
Retweet of: [[None]]
Quoted tweet: [[None]]
