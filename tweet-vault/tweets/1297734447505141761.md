---
id: 1297734447505141761
author: tdietterich
published_date: 2020-08-24 03:16:17 +00:00
conversation_id: 1296678240271171585
in_reply_to: 1297721579325894657
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- sequences
- overstating
- all
- gary
- pain
- sense
- patterns
- meaningless
- pleasure
- ml
- case
- whatever
- signals
- hunger
- gets
- innate
- long
- given
- learns
- meaning
- data
- words
- etc

---

@GaryMarcus @neuro_data @KordingLab @tdverstynen @danilobzdok @lakens @TonyZador @ylecun @criticalneuro @IrisVanRooij @neurograce @achristensen56 @AudeOliva @BlackInNeuro @BlackWomenInAI @tyrell_turing Overstating your case, here, Gary. ML learns patterns in whatever it is given. In THIS case, long sequences of words. But isn't all sense data meaningless tokens or signals at some level? Meaning gets a foothold through innate rewards: pain, pleasure, hunger, etc. 1/

[View tweet on Twitter.com](https://twitter.com/tdietterich/status/1297734447505141761)

### Metadata

Author: [[@tdietterich]]
Conversation: [[conversation-1296678240271171585]]
In reply to: [[1297721579325894657]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2020-08-24]]
keywords:
- [[index/sequences|sequences]]
- [[index/overstating|overstating]]
- [[index/all|all]]
- [[index/gary|gary]]
- [[index/pain|pain]]
- [[index/sense|sense]]
- [[index/patterns|patterns]]
- [[index/meaningless|meaningless]]
- [[index/pleasure|pleasure]]
- [[index/ml|ml]]
- [[index/case|case]]
- [[index/whatever|whatever]]
- [[index/signals|signals]]
- [[index/hunger|hunger]]
- [[index/gets|gets]]
- [[index/innate|innate]]
- [[index/long|long]]
- [[index/given|given]]
- [[index/learns|learns]]
- [[index/meaning|meaning]]
- [[index/data|data]]
- [[index/words|words]]
- [[index/etc|etc]]
