---
id: 1455527752036085762
author: 3363584909
published_date: 2021-11-02 13:30:33 +00:00
conversation_id: 1455527752036085762
---
This paper has crossed my desk: https://t.co/IO9VFNDiAn
which I've hoped would explain what the "causal confusion" is in "imitation learning," so it can be de-confused using DAGs. Unfortunately, the confusion is not articulated in a language I could understand. Anyone can help?