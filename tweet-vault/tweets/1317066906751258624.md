---
id: 1317066906751258624
author: yudapearl
published_date: 2020-10-16 11:36:35 +00:00
conversation_id: 1317066906751258624
in_reply_to: None
retweet: None
quoted_tweet: 1317057642888572928
type: tweet
tags:
keywords:
- tasks
- prevent
- forgiven
- would
- ci
- whether
- specific
- assuming
- introduce
- penalizes
- bias
- question
- impossible
- model
- dont
- distribution
- proving
- devastating
- unwanted
- want
- probability

---

Not assuming a specific model is forgiven - you dont want to introduce unwanted bias. The question is whether not assuming ANY probability distribution  penalizes you. In CI it would be devastating, for it would prevent us from proving that some model-blind tasks are impossible. https://t.co/GxtUwZA2OX

[View tweet on Twitter.com](https://twitter.com/yudapearl/status/1317066906751258624)

### Metadata

Author: [[@yudapearl]]
Conversation: [[conversation-1317066906751258624]]
In reply to: [[None]]
Retweet of: [[None]]
Quoted tweet: [[1317057642888572928]]
Published Date: [[calendar/2020-10-16]]
keywords:
- [[index/tasks|tasks]]
- [[index/prevent|prevent]]
- [[index/forgiven|forgiven]]
- [[index/would|would]]
- [[index/ci|ci]]
- [[index/whether|whether]]
- [[index/specific|specific]]
- [[index/assuming|assuming]]
- [[index/introduce|introduce]]
- [[index/penalizes|penalizes]]
- [[index/bias|bias]]
- [[index/question|question]]
- [[index/impossible|impossible]]
- [[index/model|model]]
- [[index/dont|dont]]
- [[index/distribution|distribution]]
- [[index/proving|proving]]
- [[index/devastating|devastating]]
- [[index/unwanted|unwanted]]
- [[index/want|want]]
- [[index/probability|probability]]
