---
id: 1460051724060790786
author: rao2z
published_date: 2021-11-15 01:07:12 +00:00
conversation_id: 1460051724060790786
in_reply_to: None
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- getting
- acknowledged
- nets
- coming
- causal
- causality
- handled
- ignorance
- bayes
- large
- i
- distinction
- planning
- teach
- find
- always

---

Getting ready to teach causal diagrams/do-calc as a follow-on to bayes nets in #Intro #AI.

Coming from planning, where the causation-observation distinction has always been acknowledged and handled,  I find both ignorance and hubbub re: causality in #AI at large  mystifying. 1/

[View tweet on Twitter.com](https://twitter.com/rao2z/status/1460051724060790786)

### Metadata

Author: [[@rao2z]]
Conversation: [[conversation-1460051724060790786]]
In reply to: [[None]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2021-11-15]]
keywords:
- [[index/getting|getting]]
- [[index/acknowledged|acknowledged]]
- [[index/nets|nets]]
- [[index/coming|coming]]
- [[index/causal|causal]]
- [[index/causality|causality]]
- [[index/handled|handled]]
- [[index/ignorance|ignorance]]
- [[index/bayes|bayes]]
- [[index/large|large]]
- [[index/i|i]]
- [[index/distinction|distinction]]
- [[index/planning|planning]]
- [[index/teach|teach]]
- [[index/find|find]]
- [[index/always|always]]
