---
id: 1216403594087297024
author:RandomlyWalking
published_date:{{PUBLISHED_DATE }}
conversation_id: Conversation-1216253310925037568
in_reply_to: 1216299446318714880
retweet: None
quoted_tweet: None
---

@yudapearl @raamana_ With respect, the snark here is a bit much. ML in the 2000s was exactly what you suggest: think about what inductive bias you want, and design a convex loss to encode it. This approach fell out of favor in 2010s because again and again, deep learning worked better!

### Metadata

Author: [[@RandomlyWalking]]
Conversation: [[Conversation-1216253310925037568]]
In reply to: [[1216299446318714880]]
Retweet of: [[None]]
Quoted tweet: [[None]]
