---
id: 1216403594087297024
author: RandomlyWalking
published_date: 2020-01-12 16:56:31 +00:00
conversation_id: 1216253310925037568
in_reply_to: 1216299446318714880
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- worked
- bit
- loss
- ml
- learning
- because
- bias
- exactly
- favor
- deep
- much
- encode
- want
- think
- respect
- approach
- fell
- design
- inductive

---

@yudapearl @raamana_ With respect, the snark here is a bit much. ML in the 2000s was exactly what you suggest: think about what inductive bias you want, and design a convex loss to encode it. This approach fell out of favor in 2010s because again and again, deep learning worked better!

[View tweet on Twitter.com](https://twitter.com/RandomlyWalking/status/1216403594087297024)

### Metadata

Author: [[@RandomlyWalking]]
Conversation: [[conversation-1216253310925037568]]
In reply to: [[1216299446318714880]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2020-01-12]]
keywords:
- [[index/worked|worked]]
- [[index/bit|bit]]
- [[index/loss|loss]]
- [[index/ml|ml]]
- [[index/learning|learning]]
- [[index/because|because]]
- [[index/bias|bias]]
- [[index/exactly|exactly]]
- [[index/favor|favor]]
- [[index/deep|deep]]
- [[index/much|much]]
- [[index/encode|encode]]
- [[index/want|want]]
- [[index/think|think]]
- [[index/respect|respect]]
- [[index/approach|approach]]
- [[index/fell|fell]]
- [[index/design|design]]
- [[index/inductive|inductive]]
