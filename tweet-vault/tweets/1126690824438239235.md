---
id: 1126690824438239235
author: ericjang11
published_date: 2019-05-10 03:30:00 +00:00
conversation_id: 1065280340669816832
in_reply_to: 1126687321212870658
retweet: None
quoted_tweet: None
type: tweet
tags:
keywords:
- understand
- basically
- counterfactual
- must
- q
- rl
- makes
- model
- encodes
- explicit
- agent
- ways
- implicitly
- maximizes

---

@eigenhector @yudapearl @eliasbareinboim @jasonhartford @dustinvtran @zacharylipton @CsabaSzepesvari @GaryMarcus @earnmyturns @ShalitUri Model-based RL makes the counterfactual model p(s_tp1|s, a) explicit. But Q basically encodes p(r_tp1|s, a), which is also counterfactual (in the ways that matter). An agent that maximizes reward in un-memorized envs must implicitly understand p(s_tp1|s, a).

[View tweet on Twitter.com](https://twitter.com/ericjang11/status/1126690824438239235)

### Metadata

Author: [[@ericjang11]]
Conversation: [[conversation-1065280340669816832]]
In reply to: [[1126687321212870658]]
Retweet of: [[None]]
Quoted tweet: [[None]]
Published Date: [[calendar/2019-05-10]]
keywords:
- [[index/understand|understand]]
- [[index/basically|basically]]
- [[index/counterfactual|counterfactual]]
- [[index/must|must]]
- [[index/q|q]]
- [[index/rl|rl]]
- [[index/makes|makes]]
- [[index/model|model]]
- [[index/encodes|encodes]]
- [[index/explicit|explicit]]
- [[index/agent|agent]]
- [[index/ways|ways]]
- [[index/implicitly|implicitly]]
- [[index/maximizes|maximizes]]
