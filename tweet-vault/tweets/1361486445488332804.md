---
id: 1361486445488332804
author:rdisipio
published_date:{{PUBLISHED_DATE }}
conversation_id: Conversation-1361486445488332804
in_reply_to: None
retweet: None
quoted_tweet: None
---

@yudapearl are you familiar with the concept of multi-head attention mechanism in Transformer deep neural networks and machine translation? Is there any equivalent in causal inference?

### Metadata

Author: [[@rdisipio]]
Conversation: [[Conversation-1361486445488332804]]
In reply to: [[None]]
Retweet of: [[None]]
Quoted tweet: [[None]]
