---
id: 1361486445488332804
author: rdisipio
published_date: 2021-02-16 01:23:58 +00:00
conversation_id: 1361486445488332804
in_reply_to: None
retweet: None
quoted_tweet: None
type: tweet
---

@yudapearl are you familiar with the concept of multi-head attention mechanism in Transformer deep neural networks and machine translation? Is there any equivalent in causal inference?

### Metadata

Author: [[@rdisipio]]
Conversation: [[conversation-1361486445488332804]]
In reply to: [[None]]
Retweet of: [[None]]
Quoted tweet: [[None]]
