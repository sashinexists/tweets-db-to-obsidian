---
id: 1318062381877088256
author: 811646204635287552
published_date: 2020-10-19 05:32:14 +00:00
conversation_id: [[Conversation-1317532392442286080]]
in_reply_to: [[1318062216453738496]]
retweet: None
quoted_tweet: None
---
@yudapearl @danijarh It turns out this is easy to handle. We can convert POMDP observations to Markovian states by simply concatenating all observations. In addition to the "about to choose a school" partial-state S, we also have preference info M/H, and randomization info choose=C/random=R.  5/
