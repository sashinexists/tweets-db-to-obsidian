---
id: 1318062381877088256
author:jacobmbuckman
published_date:{{PUBLISHED_DATE }}
conversation_id: Conversation-1317532392442286080
in_reply_to: 1318062216453738496
retweet: None
quoted_tweet: None
---

@yudapearl @danijarh It turns out this is easy to handle. We can convert POMDP observations to Markovian states by simply concatenating all observations. In addition to the "about to choose a school" partial-state S, we also have preference info M/H, and randomization info choose=C/random=R.  5/

### Metadata

Author: [[@jacobmbuckman]]
Conversation: [[Conversation-1317532392442286080]]
In reply to: [[1318062216453738496]]
Retweet of: [[None]]
Quoted tweet: [[None]]
