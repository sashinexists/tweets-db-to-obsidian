---
id: 1318062381877088256
author: jacobmbuckman
published_date: 2020-10-19 05:32:14 +00:00
conversation_id: 1317532392442286080
in_reply_to: 1318062216453738496
retweet: None
quoted_tweet: None
type: tweet
---

@yudapearl @danijarh It turns out this is easy to handle. We can convert POMDP observations to Markovian states by simply concatenating all observations. In addition to the "about to choose a school" partial-state S, we also have preference info M/H, and randomization info choose=C/random=R.  5/

### Metadata

Author: [[@jacobmbuckman]]
Conversation: [[conversation-1317532392442286080]]
In reply to: [[1318062216453738496]]
Retweet of: [[None]]
Quoted tweet: [[None]]
