---
id: 1053827689474375680
author:gileshooker
published_date:{{PUBLISHED_DATE }}
conversation_id: Conversation-1052680788389507073
in_reply_to: 1053777656913620992
retweet: None
quoted_tweet: None
---

@yudapearl @tdietterich Problem is that explanations aim at multiple different purposes and necessarily reflect limited human cognitive capacity. Youâ€™re right that explainable ML does not yet agree on what it is trying to achieve. A goal might be a good start.

### Metadata

Author: [[@gileshooker]]
Conversation: [[Conversation-1052680788389507073]]
In reply to: [[1053777656913620992]]
Retweet of: [[None]]
Quoted tweet: [[None]]
